import logging
import os
import openai
import aiohttp
from aiogram import Bot, Dispatcher, executor, types
from pydub import AudioSegment
from dotenv import load_dotenv

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
openai.api_key = OPENROUTER_API_KEY
openai.api_base = "https://openrouter.ai/api/v1"

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot)

# –ö–æ–º–∞–Ω–¥—ã
@dp.message_handler(commands=['start'])
async def start(message: types.Message):
    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
    keyboard.add("üé§ –ì–æ–≤–æ—Ä–∏", "üñº –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É")
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç ü§ñ. –ß—Ç–æ —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å?", reply_markup=keyboard)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
@dp.message_handler(lambda message: message.text and message.text != '')
async def handle_text(message: types.Message):
    if message.text == "üé§ –ì–æ–≤–æ—Ä–∏":
        await message.reply("–ñ–¥—É –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
    elif message.text == "üñº –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É":
        await message.reply("–ù–∞–ø–∏—à–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏.")
    else:
        response = await gpt_response(message.text)
        await message.reply(response)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö
@dp.message_handler(content_types=types.ContentType.VOICE)
async def handle_voice(message: types.Message):
    file_info = await bot.get_file(message.voice.file_id)
    file_path = file_info.file_path
    file_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"

    ogg_file = f"voice_{message.from_user.id}.ogg"
    mp3_file = f"voice_{message.from_user.id}.mp3"

    async with aiohttp.ClientSession() as session:
        async with session.get(file_url) as resp:
            with open(ogg_file, 'wb') as f:
                f.write(await resp.read())

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OGG ‚Üí MP3
    audio = AudioSegment.from_file(ogg_file)
    audio.export(mp3_file, format="mp3")

    # Speech-to-Text
    with open(mp3_file, "rb") as audio_file:
        transcript = openai.Audio.transcribe("whisper-1", audio_file)

    user_text = transcript["text"]
    await message.reply(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {user_text}")

    # GPT-–æ—Ç–≤–µ—Ç
    reply_text = await gpt_response(user_text)

    # Text-to-Speech
    audio_response = openai.Audio.speech.create(
        model="elevenlabs-tts",
        voice="nova",
        input=reply_text
    )

    out_file = f"response_{message.from_user.id}.mp3"
    with open(out_file, "wb") as f:
        f.write(audio_response.content)

    # –û—Ç–ø—Ä–∞–≤–∫–∞ –≥–æ–ª–æ—Å–æ–º
    with open(out_file, "rb") as f:
        await message.reply_voice(f, caption=reply_text)

    # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for file in [ogg_file, mp3_file, out_file]:
        if os.path.exists(file):
            os.remove(file)

# GPT —Ñ—É–Ω–∫—Ü–∏—è
async def gpt_response(prompt):
    response = openai.ChatCompletion.create(
        model="openchat/openchat-7b",
        messages=[{"role": "user", "content": prompt}]
    )
    return response['choices'][0]['message']['content']

# –ó–∞–ø—É—Å–∫
if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
