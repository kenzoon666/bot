import logging
import os
import aiohttp
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.types import ParseMode
from aiogram.contrib.middlewares.logging import LoggingMiddleware
from aiogram.utils.executor import start_webhook
from pydub import AudioSegment
from typing import Optional, Dict, Any
import openai

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–¥–æ–±–∞–≤–ª–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
BOT_TOKEN = os.getenv("BOT_TOKEN", "")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")
ELEVEN_API_KEY = os.getenv("ELEVEN_API_KEY", "")
ELEVEN_VOICE_ID = "21m00Tcm4TlvDq8ikWAM"  # Nova
WEBHOOK_HOST = os.getenv("WEBHOOK_HOST", "")
WEBHOOK_PATH = f"/webhook/{BOT_TOKEN}" if BOT_TOKEN else "/webhook"
WEBHOOK_URL = f"{WEBHOOK_HOST}{WEBHOOK_PATH}" if WEBHOOK_HOST else None
WEBAPP_PORT = int(os.getenv("PORT", "8000"))  # Render –∏—Å–ø–æ–ª—å–∑—É–µ—Ç PORT

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
required_vars = {
    "BOT_TOKEN": BOT_TOKEN,
    "OPENROUTER_API_KEY": OPENROUTER_API_KEY,
    "ELEVEN_API_KEY": ELEVEN_API_KEY,
    "WEBHOOK_HOST": WEBHOOK_HOST
}

missing_vars = [name for name, value in required_vars.items() if not value]
if missing_vars:
    raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing_vars)}")

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏
bot = Bot(
    token=BOT_TOKEN,
    parse_mode=ParseMode.HTML,
    timeout=30  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API
)
dp = Dispatcher(bot)
dp.middleware.setup(LoggingMiddleware())
user_states: Dict[int, Dict[str, Any]] = {}

# ---------- –ö–ª–∏–µ–Ω—Ç—ã –∏ —É—Ç–∏–ª–∏—Ç—ã (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏) ----------
class AudioProcessor:
    @staticmethod
    async def convert_ogg_to_mp3(ogg_path: str, mp3_path: str) -> None:
        try:
            audio = AudioSegment.from_file(ogg_path)
            audio.export(mp3_path, format="mp3", bitrate="64k")  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–∏—Ç—Ä–µ–π—Ç
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            raise

    @staticmethod
    async def cleanup_files(*files: str) -> None:
        for file in files:
            try:
                if file and os.path.exists(file):
                    os.remove(file)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {file}: {e}")

class OpenAIClient:
    def __init__(self):
        self.client = openai.OpenAI(
            api_key=OPENROUTER_API_KEY,
            base_url="https://openrouter.ai/api/v1"
        )
        self.text_model = "openchat/openchat-7b"
        self.image_model = "stabilityai/stable-diffusion-xl-1024-v1-0"  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        self.whisper_model = "whisper-1"
        self.image_size = "1024x1024"  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä

    async def transcribe_audio(self, path: str) -> Optional[str]:
        try:
            with open(path, "rb") as audio:
                result = self.client.audio.transcriptions.create(
                    file=audio,
                    model=self.whisper_model
                )
            return result.text
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None

    async def generate_text_response(self, prompt: str) -> Optional[str]:
        try:
            response = self.client.chat.completions.create(
                model=self.text_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return None

    async def generate_image(self, prompt: str) -> Optional[str]:
        try:
            response = self.client.images.generate(
                model=self.image_model,
                prompt=prompt,
                n=1,
                size=self.image_size,
                response_format="url"
            )
            return response.data[0].url
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None

class ElevenLabsClient:
    def __init__(self):
        self.api_key = ELEVEN_API_KEY
        self.voice_id = ELEVEN_VOICE_ID
        self.timeout = aiohttp.ClientTimeout(total=30)  # –¢–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤

    async def text_to_speech(self, text: str) -> Optional[bytes]:
        headers = {
            "xi-api-key": self.api_key,
            "Content-Type": "application/json",
            "accept": "audio/mpeg"
        }
        payload = {
            "text": text,
            "model_id": "eleven_monolingual_v2",  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            "voice_settings": {
                "stability": 0.7,
                "similarity_boost": 0.75
            }
        }
        try:
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                async with session.post(
                    f"https://api.elevenlabs.io/v1/text-to-speech/{self.voice_id}",
                    headers=headers,
                    json=payload
                ) as resp:
                    if resp.status == 200:
                        return await resp.read()
                    error_text = await resp.text()
                    logger.error(f"–û—à–∏–±–∫–∞ TTS: —Å—Ç–∞—Ç—É—Å {resp.status}, —Ç–µ–∫—Å—Ç: {error_text}")
        except Exception as e:
            logger.error(f"TTS –æ—à–∏–±–∫–∞: {e}")
        return None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
openai_client = OpenAIClient()
eleven_labs_client = ElevenLabsClient()

# ---------- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ (—Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫) ----------
@dp.message_handler(commands=['start', 'help'])
async def cmd_start(message: types.Message):
    keyboard = types.ReplyKeyboardMarkup(resize_keyboard=True)
    keyboard.add("üé§ –ì–æ–≤–æ—Ä–∏", "üñº –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É")
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç ü§ñ —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:\n"
        "- –û—Ç–≤–µ—á–∞—é –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
        "- –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
        "- –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é\n\n"
        "–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup=keyboard
    )
    user_states[message.from_user.id] = {"waiting_for_image_prompt": False}

@dp.message_handler(lambda msg: msg.text and msg.text.lower() == "üé§ –≥–æ–≤–æ—Ä–∏")
async def handle_voice_request(message: types.Message):
    user_states[message.from_user.id] = {"waiting_for_image_prompt": False}
    await message.reply("–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ üéôÔ∏è")

@dp.message_handler(lambda msg: msg.text and msg.text.lower() == "üñº –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É")
async def handle_image_request(message: types.Message):
    user_states[message.from_user.id] = {"waiting_for_image_prompt": True}
    await message.reply("–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å:")

@dp.message_handler(lambda msg: msg.text and user_states.get(msg.from_user.id, {}).get("waiting_for_image_prompt"))
async def handle_image_prompt(message: types.Message):
    try:
        await message.reply("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        url = await openai_client.generate_image(message.text)
        if url:
            await message.reply_photo(url, caption=f"–ó–∞–ø—Ä–æ—Å: {message.text}")
        else:
            await message.reply("üòû –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")
    except Exception as e:
        logger.error(f"Image generation error: {e}")
        await message.reply("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

@dp.message_handler(content_types=types.ContentType.TEXT)
async def handle_text(message: types.Message):
    if message.from_user.id not in user_states:
        user_states[message.from_user.id] = {"waiting_for_image_prompt": False}
    
    if user_states[message.from_user.id]["waiting_for_image_prompt"]:
        return
    
    try:
        await message.reply("‚è≥ –î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º...")
        response = await openai_client.generate_text_response(message.text)
        if response:
            if len(response) > 4000:  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Telegram –Ω–∞ –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
                response = response[:4000] + "..."
            await message.reply(response)
        else:
            await message.reply("üòû –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç")
    except Exception as e:
        logger.error(f"Text processing error: {e}")
        await message.reply("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")

@dp.message_handler(content_types=types.ContentType.VOICE)
async def handle_voice(message: types.Message):
    user_id = message.from_user.id
    ogg_path = f"temp_voice_{user_id}.ogg"
    mp3_path = f"temp_voice_{user_id}.mp3"
    tts_path = f"temp_reply_{user_id}.mp3"

    try:
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        file = await bot.get_file(message.voice.file_id)
        file_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file.file_path}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(file_url) as resp:
                if resp.status != 200:
                    raise Exception(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: —Å—Ç–∞—Ç—É—Å {resp.status}")
                with open(ogg_path, 'wb') as f:
                    f.write(await resp.read())

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
        await AudioProcessor.convert_ogg_to_mp3(ogg_path, mp3_path)
        text = await openai_client.transcribe_audio(mp3_path)
        if not text:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å")

        await message.reply(f"üé§ –í—ã —Å–∫–∞–∑–∞–ª–∏:\n\n{text}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        response = await openai_client.generate_text_response(text)
        if not response:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç")

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ä–µ—á—å
        audio = await eleven_labs_client.text_to_speech(response)
        if audio:
            with open(tts_path, 'wb') as f:
                f.write(audio)
            with open(tts_path, 'rb') as f:
                await message.reply_voice(f, caption=response[:1000] + "..." if len(response) > 1000 else response)
        else:
            await message.reply(response[:4000] + "..." if len(response) > 4000 else response)

    except Exception as e:
        logger.error(f"Voice processing error: {e}")
        await message.reply("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è")
    finally:
        await AudioProcessor.cleanup_files(ogg_path, mp3_path, tts_path)

# ---------- –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (—Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π) ----------
async def on_startup(dp):
    try:
        await bot.set_webhook(
            url=WEBHOOK_URL,
            drop_pending_updates=True
        )
        logger.info(f"–í–µ–±—Ö—É–∫ —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {WEBHOOK_URL}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤–µ–±—Ö—É–∫–∞: {e}")
        raise

async def on_shutdown(dp):
    try:
        await bot.delete_webhook()
        logger.info("–í–µ–±—Ö—É–∫ —É–¥–∞–ª–µ–Ω")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤–µ–±—Ö—É–∫–∞: {e}")
    await dp.storage.close()
    await dp.storage.wait_closed()

if __name__ == '__main__':
    try:
        logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
        start_webhook(
            dispatcher=dp,
            webhook_path=WEBHOOK_PATH,
            on_startup=on_startup,
            on_shutdown=on_shutdown,
            skip_updates=True,
            host="0.0.0.0",
            port=WEBAPP_PORT,
            ssl_context=None,  # Render —Å–∞–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç SSL
        )
    except Exception as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞: {e}")
